MODEL: null
TRAIN:
  pretrained_trans: /home/anbondaret/PycharmProjects/avery-super-resolution/external/LEMMA/checkpoints/pretrain_transformer.pth
  train_data_dir:
  - /home/anbondaret/PycharmProjects/avery-super-resolution/c/CUTE80
  batch_size: 64
  width: 128
  height: 32
  epochs: 500
  cuda: false
  ngpu: 1
  workers: 0
  resume: /home/anbondaret/PycharmProjects/avery-super-resolution/external/LEMMA/checkpoints/LEMMA-release.pth
  ckpt_dir: /home/anbondaret/PycharmProjects/avery-super-resolution/external/LEMMA/checkpoints/with_test
  voc_type: all
  saveInterval: 200
  displayInterval: 50
  adadelta: false
  lr: 0.001
  adam: true
  optimizer: Adam
  beta1: 0.5
  manualSeed: 1234
  max_len: 100
  keep_ratio: false
  down_sample_scale: 2
  VAL:
    val_data_dir:
    - /home/anbondaret/PycharmProjects/avery-super-resolution/text_data/lr_lemma
    n_vis: 10
    vis_dir: demo
    valInterval: 400
    rec_pretrained: /home/anbondaret/PycharmProjects/avery-super-resolution/external/LEMMA/checkpoints/demo.pth.tar
    moran_pretrained: /home/anbondaret/PycharmProjects/avery-super-resolution/external/LEMMA/checkpoints/moran.pth
    crnn_pretrained: /home/anbondaret/PycharmProjects/avery-super-resolution/external/LEMMA/checkpoints/crnn.pth
TEST:
  checkpoint: ''
  test_data_dir: []
CONVERT:
  image_dir: null
  lmdb_dir: null
  n_convert: 10
PositionAware:
  dataset_max_length: 25
  dataset_charset_path: /home/anbondaret/PycharmProjects/avery-super-resolution/external/LEMMA/dataset/charset_36.txt
  model_vision_attention_mode: nearest
  vision:
    checkpoint: /home/anbondaret/PycharmProjects/avery-super-resolution/external/LEMMA/checkpoints/workdir/pretrain-vision-model/best-pretrain-vision-model.pth
    loss_weight: 1.0
    attention: position
    backbone: transformer
    backbone_ln: 3
    d_model: 512
  language:
    checkpoint: /home/anbondaret/PycharmProjects/avery-super-resolution/external/LEMMA/checkpoints/workdir/pretrain-language-model/pretrain-language-model.pth
    num_layers: 4
    loss_weight: 1.0
    detach: true
    use_self_attn: false
ABINet:
  dataset_max_length: 25
  dataset_charset_path: ./dataset/charset_36.txt
  model_vision_attention_mode: nearest
  full_ckpt: /home/anbondaret/PycharmProjects/avery-super-resolution/external/LEMMA/checkpoints/workdir/train-abinet/best-train-abinet.pth
  vision:
    checkpoint: /home/anbondaret/PycharmProjects/avery-super-resolution/external/LEMMA/checkpoints/workdir/pretrain-vision-model/best-pretrain-vision-model.pth
    loss_weight: 1.0
    attention: position
    backbone: transformer
    backbone_ln: 3
    d_model: 512
  language:
    checkpoint: /home/anbondaret/PycharmProjects/avery-super-resolution/external/LEMMA/checkpoints/workdir/pretrain-language-model/pretrain-language-model.pth
    num_layers: 4
    loss_weight: 1.0
    detach: true
    use_self_attn: false
MATRN:
  dataset_charset_path: ./dataset/charset_36.txt
  dataset_max_length: 25
  model_vision_attention_mode: nearest
  full_ckpt: /home/anbondaret/PycharmProjects/avery-super-resolution/external/LEMMA/checkpoints/best-train-matrn.pth
  vision:
    checkpoint: null
    attention: position
    backbone: transformer
    backbone_ln: 3
    d_model: 512
  language:
    checkpoint: null
    num_layers: 4
    detach: true
    use_self_attn: false
PARSeq:
  full_ckpt: /home/anbondaret/PycharmProjects/avery-super-resolution/external/LEMMA/checkpoints/parseq.pt
  img_size:
  - 32
  - 128
  patch_size:
  - 4
  - 8
  embed_dim: 384
  enc_depth: 12
  enc_num_heads: 6
  enc_mlp_ratio: 4
  self.max_label_length: 25
  self.decode_ar: true
  self.refine_iters: 1
  dec_num_heads: 12
  dec_mlp_ratio: 4
  dropout: 0.1
  dec_depth: 1
  perm_num: 6
  perm_mirrored: true
  max_label_length: 25
